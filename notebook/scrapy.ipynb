{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class MofanSpider(scrapy.Spider):\n",
    "    name = \"mofan\"\n",
    "    start_urls = [\n",
    "        'https://morvanzhou.github.io/',\n",
    "    ]\n",
    "    # unseen = set()\n",
    "    # seen = set()      # 我们不在需要 set 了, 它自动去重\n",
    "    def parse(self, response):\n",
    "        yield {     # return some results\n",
    "            'title': response.css('h1::text').extract_first(default='Missing').strip().replace('\"', \"\"),\n",
    "            'url': response.url,\n",
    "        }\n",
    "\n",
    "        urls = response.css('a::attr(href)').re(r'^/.+?/$')     # find all sub urls\n",
    "        for url in urls:\n",
    "            yield response.follow(url, callback=self.parse)     # it will filter duplication automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scrapy:\n",
      "\n",
      "NAME\n",
      "    scrapy - Scrapy - a web crawling and web scraping framework written for Python\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    _monkeypatches\n",
      "    cmdline\n",
      "    commands (package)\n",
      "    conf\n",
      "    contracts (package)\n",
      "    core (package)\n",
      "    crawler\n",
      "    downloadermiddlewares (package)\n",
      "    dupefilters\n",
      "    exceptions\n",
      "    exporters\n",
      "    extension\n",
      "    extensions (package)\n",
      "    http (package)\n",
      "    interfaces\n",
      "    item\n",
      "    link\n",
      "    linkextractors (package)\n",
      "    loader (package)\n",
      "    log\n",
      "    logformatter\n",
      "    mail\n",
      "    middleware\n",
      "    pipelines (package)\n",
      "    resolver\n",
      "    responsetypes\n",
      "    selector (package)\n",
      "    settings (package)\n",
      "    shell\n",
      "    signalmanager\n",
      "    signals\n",
      "    spiderloader\n",
      "    spidermiddlewares (package)\n",
      "    spiders (package)\n",
      "    squeues\n",
      "    statscollectors\n",
      "    telnet\n",
      "    utils (package)\n",
      "    xlib (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.dict(builtins.object)\n",
      "        scrapy.item.Field\n",
      "    parsel.selector.Selector(builtins.object)\n",
      "        scrapy.selector.unified.Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)\n",
      "    scrapy.item.DictItem(collections.abc.MutableMapping, scrapy.item.BaseItem)\n",
      "        scrapy.item.Item\n",
      "    scrapy.utils.trackref.object_ref(builtins.object)\n",
      "        scrapy.http.request.Request\n",
      "            scrapy.http.request.form.FormRequest\n",
      "        scrapy.selector.unified.Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)\n",
      "        scrapy.spiders.Spider\n",
      "    \n",
      "    class Field(builtins.dict)\n",
      "     |  Container of field metadata\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Field\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      x.__getitem__(y) <==> x[y]\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |  \n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      "     |  \n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |      \n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |      \n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |  \n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  fromkeys(iterable, value=None, /) from builtins.type\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class FormRequest(scrapy.http.request.Request)\n",
      "     |  FormRequest(*args, **kwargs)\n",
      "     |  \n",
      "     |  Inherit from this class (instead of object) to a keep a record of live\n",
      "     |  instances\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FormRequest\n",
      "     |      scrapy.http.request.Request\n",
      "     |      scrapy.utils.trackref.object_ref\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_response(response, formname=None, formid=None, formnumber=0, formdata=None, clickdata=None, dont_click=False, formxpath=None, formcss=None, **kwargs) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from scrapy.http.request.Request:\n",
      "     |  \n",
      "     |  __repr__ = __str__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Return a copy of this Request\n",
      "     |  \n",
      "     |  replace(self, *args, **kwargs)\n",
      "     |      Create a new Request with the same attributes except for those\n",
      "     |      given new values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from scrapy.http.request.Request:\n",
      "     |  \n",
      "     |  encoding\n",
      "     |  \n",
      "     |  meta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from scrapy.http.request.Request:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  body\n",
      "     |  \n",
      "     |  url\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from scrapy.utils.trackref.object_ref:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Item(DictItem)\n",
      "     |  Item(*args, **kwargs)\n",
      "     |  \n",
      "     |  Base class for all scraped items.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Item\n",
      "     |      DictItem\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      BaseItem\n",
      "     |      scrapy.utils.trackref.object_ref\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  fields = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DictItem:\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from DictItem:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x000001F04AED4130>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  update(self, other=(), /, **kwds)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __reversed__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Collection:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from scrapy.item.ItemMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from scrapy.utils.trackref.object_ref:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Request(scrapy.utils.trackref.object_ref)\n",
      "     |  Request(*args, **kwargs)\n",
      "     |  \n",
      "     |  Inherit from this class (instead of object) to a keep a record of live\n",
      "     |  instances\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Request\n",
      "     |      scrapy.utils.trackref.object_ref\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, url, callback=None, method='GET', headers=None, body=None, cookies=None, meta=None, encoding='utf-8', priority=0, dont_filter=False, errback=None, flags=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__ = __str__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Return a copy of this Request\n",
      "     |  \n",
      "     |  replace(self, *args, **kwargs)\n",
      "     |      Create a new Request with the same attributes except for those\n",
      "     |      given new values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  encoding\n",
      "     |  \n",
      "     |  meta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  body\n",
      "     |  \n",
      "     |  url\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from scrapy.utils.trackref.object_ref:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)\n",
      "     |  Selector(*args, **kwargs)\n",
      "     |  \n",
      "     |  An instance of :class:`Selector` is a wrapper over response to select\n",
      "     |  certain parts of its content.\n",
      "     |  \n",
      "     |  ``response`` is an :class:`~scrapy.http.HtmlResponse` or an\n",
      "     |  :class:`~scrapy.http.XmlResponse` object that will be used for selecting\n",
      "     |  and extracting data.\n",
      "     |  \n",
      "     |  ``text`` is a unicode string or utf-8 encoded text for cases when a\n",
      "     |  ``response`` isn't available. Using ``text`` and ``response`` together is\n",
      "     |  undefined behavior.\n",
      "     |  \n",
      "     |  ``type`` defines the selector type, it can be ``\"html\"``, ``\"xml\"``\n",
      "     |  or ``None`` (default).\n",
      "     |  \n",
      "     |  If ``type`` is ``None``, the selector automatically chooses the best type\n",
      "     |  based on ``response`` type (see below), or defaults to ``\"html\"`` in case it\n",
      "     |  is used together with ``text``.\n",
      "     |  \n",
      "     |  If ``type`` is ``None`` and a ``response`` is passed, the selector type is\n",
      "     |  inferred from the response type as follows:\n",
      "     |  \n",
      "     |  * ``\"html\"`` for :class:`~scrapy.http.HtmlResponse` type\n",
      "     |  * ``\"xml\"`` for :class:`~scrapy.http.XmlResponse` type\n",
      "     |  * ``\"html\"`` for anything else\n",
      "     |  \n",
      "     |  Otherwise, if ``type`` is set, the selector type will be forced and no\n",
      "     |  detection will occur.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Selector\n",
      "     |      parsel.selector.Selector\n",
      "     |      scrapy.utils.trackref.object_ref\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, response=None, text=None, type=None, root=None, _root=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  extract_unquoted(self)\n",
      "     |  \n",
      "     |  select(self, xpath)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  response\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  selectorlist_cls = <class 'scrapy.selector.unified.SelectorList'>\n",
      "     |      The :class:`SelectorList` class is a subclass of the builtin ``list``\n",
      "     |      class, which provides a few additional methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from parsel.selector.Selector:\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Return ``True`` if there is any real content selected or ``False``\n",
      "     |      otherwise.  In other words, the boolean value of a :class:`Selector` is\n",
      "     |      given by the contents it selects.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __nonzero__ = __bool__(self)\n",
      "     |  \n",
      "     |  __repr__ = __str__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  css(self, query)\n",
      "     |      Apply the given CSS selector and return a :class:`SelectorList` instance.\n",
      "     |      \n",
      "     |      ``query`` is a string containing the CSS selector to apply.\n",
      "     |      \n",
      "     |      In the background, CSS queries are translated into XPath queries using\n",
      "     |      `cssselect`_ library and run ``.xpath()`` method.\n",
      "     |      \n",
      "     |      .. _cssselect: https://pypi.python.org/pypi/cssselect/\n",
      "     |  \n",
      "     |  extract = get(self)\n",
      "     |  \n",
      "     |  get(self)\n",
      "     |      Serialize and return the matched nodes in a single unicode string.\n",
      "     |      Percent encoded content is unquoted.\n",
      "     |  \n",
      "     |  getall(self)\n",
      "     |      Serialize and return the matched node in a 1-element list of unicode strings.\n",
      "     |  \n",
      "     |  re(self, regex, replace_entities=True)\n",
      "     |      Apply the given regex and return a list of unicode strings with the\n",
      "     |      matches.\n",
      "     |      \n",
      "     |      ``regex`` can be either a compiled regular expression or a string which\n",
      "     |      will be compiled to a regular expression using ``re.compile(regex)``.\n",
      "     |      \n",
      "     |      By default, character entity references are replaced by their\n",
      "     |      corresponding character (except for ``&amp;`` and ``&lt;``).\n",
      "     |      Passing ``replace_entities`` as ``False`` switches off these\n",
      "     |      replacements.\n",
      "     |  \n",
      "     |  re_first(self, regex, default=None, replace_entities=True)\n",
      "     |      Apply the given regex and return the first unicode string which\n",
      "     |      matches. If there is no match, return the default value (``None`` if\n",
      "     |      the argument is not provided).\n",
      "     |      \n",
      "     |      By default, character entity references are replaced by their\n",
      "     |      corresponding character (except for ``&amp;`` and ``&lt;``).\n",
      "     |      Passing ``replace_entities`` as ``False`` switches off these\n",
      "     |      replacements.\n",
      "     |  \n",
      "     |  register_namespace(self, prefix, uri)\n",
      "     |      Register the given namespace to be used in this :class:`Selector`.\n",
      "     |      Without registering namespaces you can't select or extract data from\n",
      "     |      non-standard namespaces. See :ref:`selector-examples-xml`.\n",
      "     |  \n",
      "     |  remove_namespaces(self)\n",
      "     |      Remove all namespaces, allowing to traverse the document using\n",
      "     |      namespace-less xpaths. See :ref:`removing-namespaces`.\n",
      "     |  \n",
      "     |  xpath(self, query, namespaces=None, **kwargs)\n",
      "     |      Find nodes matching the xpath ``query`` and return the result as a\n",
      "     |      :class:`SelectorList` instance with all elements flattened. List\n",
      "     |      elements implement :class:`Selector` interface too.\n",
      "     |      \n",
      "     |      ``query`` is a string containing the XPATH query to apply.\n",
      "     |      \n",
      "     |      ``namespaces`` is an optional ``prefix: namespace-uri`` mapping (dict)\n",
      "     |      for additional prefixes to those registered with ``register_namespace(prefix, uri)``.\n",
      "     |      Contrary to ``register_namespace()``, these prefixes are not\n",
      "     |      saved for future calls.\n",
      "     |      \n",
      "     |      Any additional named arguments can be used to pass values for XPath\n",
      "     |      variables in the XPath expression, e.g.::\n",
      "     |      \n",
      "     |          selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from parsel.selector.Selector:\n",
      "     |  \n",
      "     |  attrib\n",
      "     |      Return the attributes dictionary for underlying element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from parsel.selector.Selector:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  namespaces\n",
      "     |  \n",
      "     |  root\n",
      "     |  \n",
      "     |  text\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from scrapy.utils.trackref.object_ref:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Spider(scrapy.utils.trackref.object_ref)\n",
      "     |  Spider(*args, **kwargs)\n",
      "     |  \n",
      "     |  Base class for scrapy spiders. All spiders must inherit from this\n",
      "     |  class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Spider\n",
      "     |      scrapy.utils.trackref.object_ref\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__ = __str__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  log(self, message, level=10, **kw)\n",
      "     |      Log the given message at the given log level\n",
      "     |      \n",
      "     |      This helper wraps a log call to the logger within the spider, but you\n",
      "     |      can use it directly (e.g. Spider.logger.info('msg')) or use any other\n",
      "     |      Python logger too.\n",
      "     |  \n",
      "     |  make_requests_from_url(self, url)\n",
      "     |      This method is deprecated.\n",
      "     |  \n",
      "     |  parse(self, response)\n",
      "     |  \n",
      "     |  set_crawler(self, crawler)\n",
      "     |  \n",
      "     |  start_requests(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_crawler(crawler, *args, **kwargs) from builtins.type\n",
      "     |  \n",
      "     |  handles_request(request) from builtins.type\n",
      "     |  \n",
      "     |  update_settings(settings) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  close(spider, reason)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  logger\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  custom_settings = None\n",
      "     |  \n",
      "     |  name = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from scrapy.utils.trackref.object_ref:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['__version__', 'version_info', 'twisted_version', 'Spider',...\n",
      "    twisted_version = (19, 10, 0)\n",
      "    version_info = (1, 6, 0)\n",
      "\n",
      "VERSION\n",
      "    1.6.0\n",
      "\n",
      "FILE\n",
      "    d:\\programdata\\anaconda3\\envs\\scrapy\\lib\\site-packages\\scrapy\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scrapy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
